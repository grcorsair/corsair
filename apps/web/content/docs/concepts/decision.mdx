---
title: "Advanced: Automated Decisions"
description: "Automated audit, continuous certification, and third-party risk management."
section: "concepts"
order: 13
---

## Overview

The decision features automate compliance workflows using signed proofs from the five primitives and quality scores from the intelligence layer. While the primitives create verifiable evidence and the scoring engine rates it, the decision features act on it: running audits, managing certifications, and assessing vendor risk.

Three engines compose the decision layer:

| Engine | CLI Command | What It Does |
|--------|-------------|--------------|
| **Audit** | `corsair audit` | Combine multiple evidence files, score, generate findings |
| **Certification** | `corsair cert` | Continuous certification lifecycle with drift detection |
| **TPRM** | `corsair tprm` | Vendor risk assessment using CPOEs |

## Audit Engine

The audit engine orchestrates the complete compliance audit pipeline: ingest evidence files, normalize, score, generate findings, and optionally run governance checks. It combines what `corsair sign` does for individual files into a comprehensive multi-file audit operation.

### Pipeline

```
1. Read evidence files from scope
2. Parse each file (auto-detect or format override)
3. Normalize to canonical form
4. Filter excluded controls
5. Score combined evidence
6. Run governance checks (optional, Quartermaster)
7. Generate findings from normalized evidence
8. Compute summary statistics
9. Return complete AuditResult
```

### CLI Usage

```bash
# Basic audit with framework targeting
corsair audit \
  --files prowler.json inspec.json trivy.json \
  --scope "AWS Production Environment" \
  --frameworks SOC2,NIST-800-53

# With governance review
corsair audit \
  --files prowler.json inspec.json \
  --scope "AWS Production" \
  --frameworks SOC2 \
  --governance

# Exclude specific controls
corsair audit \
  --files evidence/*.json \
  --scope "Cloud Infrastructure" \
  --frameworks SOC2 \
  --exclude CC7.3,CC7.4

# JSON output for programmatic consumption
corsair audit \
  --files prowler.json \
  --scope "AWS Production" \
  --json
```

### Audit Scope

Every audit is scoped by name, target frameworks, and evidence files:

```typescript
interface AuditScope {
  name: string;             // Human-readable scope (e.g., "AWS Production Environment")
  frameworks: string[];     // Target frameworks (e.g., ["SOC2", "NIST-800-53"])
  evidencePaths: string[];  // File paths for evidence files
  formats?: string[];       // Optional format overrides (same index as evidencePaths)
  excludeControls?: string[]; // Control IDs to exclude from scope
}
```

### Finding Categories

The audit engine generates findings across five categories, sorted by severity (critical first):

| Category | Severity | What It Detects |
|----------|----------|-----------------|
| **failure** | matches control | Failed controls (severity matches the control's own severity) |
| **gap** | medium | Controls with no assessment evidence (skipped + empty summary) |
| **weakness** | low | L0-only controls (self-assessed, document evidence only) |
| **strength** | info | Passed critical controls (positive observation) |
| **observation** | varies | Inconsistencies or notable patterns |

Each finding includes:

```typescript
interface AuditFinding {
  id: string;             // e.g., "CRIT-001", "HIGH-002", "GAP-003"
  severity: string;       // "critical" | "high" | "medium" | "low" | "info"
  category: string;       // "failure" | "gap" | "weakness" | "strength" | "observation"
  controlId: string;      // Related control identifier
  title: string;          // Short finding title
  description: string;    // Detailed description
  recommendation?: string; // Remediation recommendation
  evidence: {
    source: string;       // Source tool
    controlStatus: string; // Control status
  };
}
```

### Audit Configuration

| Option | Default | Description |
|--------|---------|-------------|
| `includeGovernance` | `false` | Run Quartermaster governance checks |
| `includeScore` | `true` | Run the scoring engine |
| `generateFindings` | `true` | Generate findings from evidence |
| `signResult` | `false` | Sign the audit result as a CPOE |
| `outputFormat` | `"json"` | Output format: `json`, `summary`, or `full` |

### Multi-Agent Orchestration

For large audits, the orchestrator splits work across parallel agents and merges results. This is the "4 agents audit AWS in 15 minutes" feature.

#### Split Strategies

| Strategy | How Work Is Divided |
|----------|-------------------|
| **by-file** | Each agent gets a subset of evidence files (round-robin distribution) |
| **by-framework** | Each agent handles specific frameworks (all files, filtered by framework) |
| **by-domain** | Files are classified by domain pattern (network, identity, data, infra) and each agent handles a domain |

Domain patterns for `by-domain`:

| Domain | Filename Pattern |
|--------|-----------------|
| network | `network`, `firewall`, `waf`, `ddos`, `vpc`, `subnet`, `sg` |
| identity | `identity`, `iam`, `auth`, `mfa`, `sso`, `access` |
| data | `data`, `encrypt`, `storage`, `s3`, `rds`, `backup`, `db` |
| infra | `infra`, `patch`, `config`, `compute`, `ec2`, `lambda`, `container` |

Files that do not match any pattern go to a "general" agent.

#### Orchestration Pipeline

```
1. planAudit()       -- Split work across agents by strategy
2. executeParallel() -- Run all agents concurrently via Promise.allSettled
3. mergeResults()    -- Combine agent results, deduplicate findings
```

Or use the convenience method:

```bash
# Orchestrated audit (4 agents, by-file strategy)
corsair audit \
  --files scan-results/*.json \
  --scope "Full Infrastructure" \
  --frameworks SOC2,NIST-800-53 \
  --orchestrate \
  --agents 4 \
  --strategy by-file
```

#### Merged Results

Agent results are combined with:

- **Control counts** summed across agents
- **Findings deduplicated** by `controlId:category`, keeping the highest severity
- **Composite score** calculated as weighted average by control count
- **Parallel speedup** measured as sequential time / actual time

The orchestration report shows per-agent scores, composite score, and speedup:

```
CORSAIR MULTI-AGENT AUDIT REPORT
==================================================
Scope: Full Infrastructure
Strategy: by-file (4 agents)
Duration: 3.2s (3.8x speedup)

AGENT RESULTS:
  ok  agent-1          87/100 (B)
  ok  agent-2          92/100 (A)
  ok  agent-3          78/100 (C)
  ok  agent-4          85/100 (B)

COMPOSITE: 86/100 (B)
Controls: 184 total, 162 passed, 18 failed, 4 skipped
Findings: 2 critical, 5 high, 8 medium
```

## Certification Engine

The certification engine manages ongoing compliance certifications with lifecycle tracking, drift detection, and policy-based automation. Think of it as the state machine that keeps a certification valid over time.

### Certification Lifecycle

```
                 create
                   |
                   v
  +--------+  renew(pass)  +--------+
  | active |<------------- | warning|
  +--------+               +--------+
      |                        |
      | score drops            | score drops
      v                        v
  +--------+   grace period  +----------+
  | warning|  ------------> | degraded  |
  +--------+                +----------+
                                |
                   auto-suspend | (grace expired or severe drift)
                                v
                          +-----------+
                          | suspended |
                          +-----------+
                                |
                   renew(pass)  |
                                v
                          +---------+
                          | active  |
                          +---------+
```

### Status States

| Status | Meaning | Trigger |
|--------|---------|---------|
| **active** | Certified, all checks passing | Score >= warning threshold |
| **warning** | Certified but score degrading | Score between minimum and warning |
| **degraded** | Below threshold, in grace period | Score < minimum threshold |
| **suspended** | Certification suspended | Grace period expired or severe drift |
| **expired** | Not renewed in time | Audit interval + grace period exceeded |
| **revoked** | Manually revoked (terminal) | Explicit revocation |

### CLI Usage

```bash
# Create a certification with initial audit
corsair cert create \
  --scope "AWS Production" \
  --frameworks SOC2 \
  --files evidence/*.json \
  --min-score 70 \
  --warning-threshold 80

# Check certification status
corsair cert check <cert-id>

# Renew with fresh evidence
corsair cert renew <cert-id> --files new-evidence/*.json

# Suspend a certification
corsair cert suspend <cert-id> --reason "Compliance drift detected"

# Revoke a certification
corsair cert revoke <cert-id> --reason "Vendor terminated"

# List expiring certifications
corsair cert expiring --within 30
```

### Certification Policy

Each certification is governed by a policy that defines thresholds, schedules, and automation behavior:

```typescript
interface CertificationPolicy {
  id: string;
  name: string;
  scope: AuditScope;

  // Thresholds
  minimumScore: number;        // Score below this = degraded (default: 70)
  warningThreshold: number;    // Score below this = warning (default: 80)

  // Schedule
  auditIntervalDays: number;   // Re-audit frequency (default: 90)
  freshnessMaxDays: number;    // Max evidence age (default: 7)
  gracePeriodDays: number;     // Days below threshold before suspension (default: 14)

  // Automation
  autoRenew: boolean;          // Auto-renew on passing audit
  autoSuspend: boolean;        // Auto-suspend on drift
  notifyOnChange: boolean;     // Send FLAGSHIP signal on status change
}
```

### Drift Detection

On every renewal, the certification engine compares the new audit against the previous one:

```typescript
interface DriftReport {
  certificationId: string;
  detectedAt: string;
  previousScore: number;
  currentScore: number;
  scoreDelta: number;
  degradedControls: Array<{
    controlId: string;
    previousStatus: string;     // e.g., "pass"
    currentStatus: string;      // e.g., "fail"
    severity: string;
  }>;
  recommendation: "monitor" | "investigate" | "suspend";
}
```

| Score Delta | Recommendation |
|-------------|---------------|
| 0-5 point drop | `monitor` -- Watch but take no action |
| 5-15 point drop | `investigate` -- Security team should review |
| Below minimum score | `suspend` -- Certification at risk |

When `autoSuspend` is enabled in the policy, a "suspend" recommendation automatically transitions the certification to `suspended` status.

### Status History

Every status transition is recorded for audit trail:

```typescript
statusHistory: Array<{
  status: CertificationStatus;
  changedAt: string;            // ISO 8601
  reason: string;               // Why the status changed
  score?: number;               // Score at time of change
}>;
```

## TPRM Engine

The TPRM (Third-Party Risk Management) engine automates vendor risk assessment using CPOEs as the evidence layer. It replaces questionnaire-based vendor assessment with cryptographically verifiable CPOE-based evaluation.

### Pipeline

```
registerVendor -> requestAssessment -> runAssessment -> getDashboard
```

### CLI Usage

```bash
# Register a vendor
corsair tprm register \
  --name "Acme Cloud" \
  --domain acme.com \
  --did "did:web:acme.com" \
  --risk-tier high \
  --tags cloud,data-processor

# Request an assessment
corsair tprm request \
  --vendor <vendor-id> \
  --frameworks SOC2,ISO27001 \
  --min-score 70 \
  --min-assurance 1

# Run assessment against vendor CPOEs
corsair tprm assess \
  --request <request-id> \
  --cpoes vendor-cpoe-1.jwt vendor-cpoe-2.jwt

# View vendor dashboard
corsair tprm dashboard

# List vendors by risk tier
corsair tprm vendors --risk-tier critical
```

### Five-Dimension Composite Scoring

The TPRM engine calculates a composite vendor risk score from 5 weighted dimensions (weights sum to 1.0):

| # | Dimension | Weight | What It Measures | Score Range |
|---|-----------|--------|------------------|-------------|
| 1 | **Evidence Quality** | 0.30 | Average CPOE composite score across all vendor CPOEs | 0-100 |
| 2 | **Certification Status** | 0.25 | Best certification status: active=100, warning=75, degraded=50, suspended=25, expired=10, revoked=0, none=30 | 0-100 |
| 3 | **Framework Coverage** | 0.20 | Percentage of required frameworks covered by vendor CPOEs | 0-100 |
| 4 | **Freshness** | 0.15 | Evidence age penalty (linear decay, configurable window, default 90 days) | 0-100 |
| 5 | **Historical Trend** | 0.10 | Improving (100), stable (80), slight degradation (60), significant degradation (30), no history (70) | 0-100 |

### Automated Decisions

Based on the composite score, the engine makes one of four decisions:

| Decision | Condition | Meaning |
|----------|-----------|---------|
| **approved** | Score >= 85 | Vendor meets all compliance requirements |
| **conditional** | Score >= 70 | Vendor is acceptable with conditions (missing frameworks, stale evidence, etc.) |
| **review_required** | Score >= 50 | Manual review by security team required |
| **rejected** | Score < 50 | Vendor does not meet minimum compliance requirements |

Thresholds are configurable:

```typescript
interface TPRMConfig {
  autoApproveThreshold: number;   // Default: 85
  reviewThreshold: number;        // Default: 70
  rejectThreshold: number;        // Default: 50
  freshnessWeightDays: number;    // Default: 90
  trendWindowDays: number;        // Default: 180
}
```

### Assessment Findings

The engine generates findings for specific risk issues:

| Category | Severity | What It Detects |
|----------|----------|-----------------|
| `missing_cpoe` | critical | No CPOEs provided for assessment |
| `expired_cpoe` | high | A CPOE has expired |
| `low_score` | high | Evidence quality below minimum threshold |
| `missing_framework` | high | Required framework not covered by any CPOE |
| `no_certification` | medium | Vendor has no active compliance certification |
| `stale_evidence` | medium | Evidence exceeds freshness threshold |
| `drift_detected` | varies | Compliance drift detected between assessments |

### Vendor Monitoring

Configure ongoing monitoring for registered vendors:

```typescript
interface MonitoringConfig {
  vendorId: string;
  enabled: boolean;
  checkIntervalDays: number;      // Default: 7
  alertOnScoreDrop: number;       // Alert if score drops by N points
  alertOnStatusChange: boolean;   // Alert on certification status change
  alertOnExpiry: boolean;         // Alert N days before CPOE expires
  expiryWarningDays: number;      // Default: 30
}
```

Monitoring generates alerts for:

| Alert Type | Trigger |
|-----------|---------|
| `score_drop` | Vendor score dropped by configured threshold |
| `status_change` | Certification status changed |
| `expiry_warning` | CPOE approaching expiry |

### TPRM Dashboard

The dashboard provides an aggregate view of all vendor risk:

```typescript
interface TPRMDashboard {
  totalVendors: number;
  byRiskTier: Record<RiskTier, number>;       // { critical: 2, high: 5, medium: 12, low: 8, minimal: 3 }
  byDecision: Record<AssessmentDecision, number>; // { approved: 15, conditional: 8, review_required: 3, rejected: 1 }
  averageScore: number;
  vendorsNeedingReview: number;
  expiringAssessments: number;
  recentAssessments: AssessmentResult[];       // Last 10, newest first
}
```

### Vendor Profiles

Each vendor is registered with identity and risk classification:

```typescript
interface VendorProfile {
  id: string;
  name: string;
  domain: string;            // did:web domain (e.g., "acme.com")
  did: string;               // Full DID (e.g., "did:web:acme.com")
  riskTier: RiskTier;        // "critical" | "high" | "medium" | "low" | "minimal"
  tags: string[];            // e.g., ["cloud", "data-processor", "subprocessor"]
  contacts?: Array<{ name: string; email: string; role: string }>;
}
```

## How Everything Connects

```
Five Primitives: Sign, Verify, Diff, Log, Signal
    |
    | Signed CPOEs, verified evidence, transparency log
    v
Intelligence: Normalize, Score, Query, Quartermaster
    |
    | Canonical controls, quality scores, governance findings
    v
Decisions: Audit, Certification, TPRM
    |
    | Audit results, certification status, vendor decisions
    v
Outcome: approve/deny/suspend/renew decisions backed by cryptographic proof
```

Each level adds value without replacing what's below it. A CPOE is verifiable without scoring (primitives alone). A score is meaningful without an audit workflow (intelligence alone). But the full stack -- signed evidence, scored quality, automated decisions -- replaces questionnaire-based compliance theater with cryptographically verifiable proof.
